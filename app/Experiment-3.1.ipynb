{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7382dabc-e68f-43a7-accb-830dcff4c53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-24 22:21:12.782805: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-24 22:21:12.791027: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-24 22:21:12.813678: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-24 22:21:12.851009: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-24 22:21:12.861306: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-24 22:21:12.898665: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-24 22:21:14.903775: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a541057a-9a4e-494a-8f7a-2bd0a71ce085",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n",
    "This section outlines the steps involved in processing the data before further analysis or modeling.\n",
    "\n",
    "\n",
    "1. General Data Processing.\n",
    "\n",
    "2. Convert the following fields to lowercase for uniformity:\n",
    "   - **Name**\n",
    "   - **fieldlabel**\n",
    "\n",
    "   This ensures that comparisons are case-insensitive.\n",
    "\n",
    "## Grouping Forms\n",
    "\n",
    "3. Group the forms based on:\n",
    "   - **Form ID**(customform)\n",
    "   - **name**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02b7f348-1a0f-4fdc-9b2e-00b2d9419ac5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customform</th>\n",
       "      <th>name</th>\n",
       "      <th>fieldlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>770</td>\n",
       "      <td>projektportefølje</td>\n",
       "      <td>[projekt nr., oprettet den, oprettet af, proje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>775</td>\n",
       "      <td>projektområde</td>\n",
       "      <td>[tekst]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>876</td>\n",
       "      <td>claims</td>\n",
       "      <td>[processor, description of claim, complaint ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>876</td>\n",
       "      <td>kundereklamation</td>\n",
       "      <td>[vælg kunde, gadenavn, postnr, by, telefonnumm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>876</td>\n",
       "      <td>reklamation</td>\n",
       "      <td>[vælg kunde, e-mail, kontaktperson, behandles ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>2584010</td>\n",
       "      <td>formularkatalog</td>\n",
       "      <td>[oprettet af, oprettet, blank linje, seneste æ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>2584018</td>\n",
       "      <td>formularkatalog - kategori</td>\n",
       "      <td>[kategori]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>2584251</td>\n",
       "      <td>formularkatalog - øvrige vurderinger</td>\n",
       "      <td>[hvad gør formularen god?, vurderet af, vurder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>2584255</td>\n",
       "      <td>formularkatalog - vurderingsskala</td>\n",
       "      <td>[vurdering]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>2597892</td>\n",
       "      <td>vidensdeling</td>\n",
       "      <td>[emne, uddybende beskrivelse]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>859 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     customform                                  name  \\\n",
       "0           770                     projektportefølje   \n",
       "1           775                         projektområde   \n",
       "2           876                                claims   \n",
       "3           876                      kundereklamation   \n",
       "4           876                           reklamation   \n",
       "..          ...                                   ...   \n",
       "854     2584010                       formularkatalog   \n",
       "855     2584018            formularkatalog - kategori   \n",
       "856     2584251  formularkatalog - øvrige vurderinger   \n",
       "857     2584255     formularkatalog - vurderingsskala   \n",
       "858     2597892                          vidensdeling   \n",
       "\n",
       "                                            fieldlabel  \n",
       "0    [projekt nr., oprettet den, oprettet af, proje...  \n",
       "1                                              [tekst]  \n",
       "2    [processor, description of claim, complaint ca...  \n",
       "3    [vælg kunde, gadenavn, postnr, by, telefonnumm...  \n",
       "4    [vælg kunde, e-mail, kontaktperson, behandles ...  \n",
       "..                                                 ...  \n",
       "854  [oprettet af, oprettet, blank linje, seneste æ...  \n",
       "855                                         [kategori]  \n",
       "856  [hvad gør formularen god?, vurderet af, vurder...  \n",
       "857                                        [vurdering]  \n",
       "858                      [emne, uddybende beskrivelse]  \n",
       "\n",
       "[859 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('data/all_data.csv', on_bad_lines='skip')\n",
    "\n",
    "#handle blocktype(removeit).\n",
    "indices_to_drop = df[df['elementtype'] == 'block'].index\n",
    "df = df.drop(indices_to_drop)\n",
    "\n",
    "#put specialtype in place.\n",
    "for index, row in df.iterrows():\n",
    "    if row['elementtype'] == 'special' and pd.isnull(row['fieldtype']):  # Check if 'elementtype' is empty\n",
    "        df.at[index, 'fieldtype'] = row['specialtype']  # Assign 'specialtype' value to 'elementtype'\n",
    "\n",
    "df = df.drop(columns=['Kunde','fieldtype','specialtype','elementtype', 'customname','fieldobjectid','fieldparentid','fieldparenttype','blocktype','fieldrelation','language'])\n",
    "df['fieldlabel'] = df['fieldlabel'].apply(str.lower)\n",
    "df['name'] = df['name'].apply(str.lower)\n",
    "data = df.groupby(['customform','name'])['fieldlabel'].apply(list).reset_index()\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af3b3db-072a-467b-a6b9-c90712c6211d",
   "metadata": {},
   "source": [
    "# Prepare Data for Training\n",
    "\n",
    "## Create a Mapping Between Label and Index\n",
    "\n",
    "1. **Label to Index Mapping**:  \n",
    "   Create a mapping between the **field label** and a unique index. This allows us to efficiently handle categorical data during training.\n",
    "\n",
    "## Create Encoding for \"Field Label\"\n",
    "\n",
    "2. **Field Label Encoding**:  \n",
    "   Encode the **\"fieldlabel\"** by counting how many times each label appears within a form. This gives us a numeric representation of label frequency in the form.\n",
    "\n",
    "## Create Embedding for \"Form Name\"\n",
    "\n",
    "3. **Form Name Embedding**:  \n",
    "   Create an embedding for the **\"form name\"** using Tokenizer This will convert the form name into a dense vector representation.\n",
    "\n",
    "## Pad the Embedding\n",
    "\n",
    "4. **Padding the Embedding**:  \n",
    "   To ensure uniformity in input length, **pad the embeddings** so that all embeddings have the same length. This is necessary for feeding the data into a model.\n",
    "\n",
    "## Split the Data for Testing\n",
    "\n",
    "5. **Testing Data Split**:  \n",
    "   Split the dataset, keeping the last **100 forms** aside for testing purposes. This will allow us to evaluate the performance of the model on unseen data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc156d01-d6aa-473d-b31c-b9c7682f6917",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get all unique labels\n",
    "all_labels = list(set(label for labels in data['fieldlabel'] for label in labels))\n",
    "\n",
    "# Map labels to indices\n",
    "label_to_index = {label: i for i, label in enumerate(all_labels)}\n",
    "index_to_label = {i: label for label, i in label_to_index.items()}\n",
    "\n",
    "# Total number of examples\n",
    "total_samples = len(data)\n",
    "\n",
    "# Split index (last 100 for testing, adjust for your data size)\n",
    "split_index = max(0, total_samples - 100)\n",
    "\n",
    "# Training and test split\n",
    "train_data = data.iloc[:split_index]  # First part for training\n",
    "test_data = data.iloc[split_index:]  # Last 100 for testing\n",
    "\n",
    "# Prepare training data\n",
    "X_train_names = train_data['name'].tolist()\n",
    "Y_train_labels = np.zeros((len(train_data), len(all_labels)), dtype=np.float32)\n",
    "\n",
    "#set one-hot encoding for field labels\n",
    "for i, labels in enumerate(train_data['fieldlabel']):\n",
    "    Y_train_labels[i, [label_to_index[label] for label in labels]] = 1\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train_names) \n",
    "X_train_sequences = tokenizer.texts_to_sequences(X_train_names)\n",
    "max_name_len = max(len(seq) for seq in X_train_sequences)  \n",
    "X_train_padded = pad_sequences(X_train_sequences, maxlen=max_name_len, padding='post')\n",
    "\n",
    "\n",
    "# Prepare test data\n",
    "X_test_names = test_data['name'].tolist()\n",
    "Y_test_labels = np.zeros((len(test_data), len(all_labels)), dtype=np.float32)\n",
    "\n",
    "for i, labels in enumerate(test_data['fieldlabel']):\n",
    "    for label in labels:\n",
    "        Y_test_labels[i, label_to_index[label]] = 1\n",
    "\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test_names)\n",
    "X_test_padded = pad_sequences(X_test_sequences, maxlen=max_name_len, padding='post')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94364fc4-6043-4e4b-8255-f1f981bc8812",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "\n",
    "The model is composed of two main components:\n",
    "\n",
    "### 1. LSTM (Sequence to Vector)\n",
    "\n",
    "- **Purpose**: The first part of the model uses an **LSTM** (Long Short-Term Memory) network. This component is designed to process the sequence of embedded form names and convert them into a vector representation.\n",
    "  \n",
    "- **Input**: The input to the LSTM is the **embedded form name**, which has been preprocessed and embedded into a vector format.\n",
    "  \n",
    "- **Output**: The output of the LSTM is a dense vector that represents the form, capturing the sequence of the form name and its contextual information.\n",
    "\n",
    "### 2. Multi-output Classifier\n",
    "\n",
    "- **Purpose**: The second part of the model is a **multi-output classifier**. This classifier predicts the probability of the appearance of each label in a given form.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "022cf4a7-09c7-4d7d-a0de-7be46d658080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.0156 - loss: 0.2738\n",
      "Epoch 2/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.0049 - loss: 0.0369\n",
      "Epoch 3/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.0132 - loss: 0.0221\n",
      "Epoch 4/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0274 - loss: 0.0161\n",
      "Epoch 5/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0157 - loss: 0.0139\n",
      "Epoch 6/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0146 - loss: 0.0120\n",
      "Epoch 7/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0170 - loss: 0.0117\n",
      "Epoch 8/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0149 - loss: 0.0120\n",
      "Epoch 9/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0251 - loss: 0.0107\n",
      "Epoch 10/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.0518 - loss: 0.0117\n",
      "Epoch 11/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0343 - loss: 0.0103\n",
      "Epoch 12/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0278 - loss: 0.0115\n",
      "Epoch 13/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0422 - loss: 0.0111\n",
      "Epoch 14/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.0568 - loss: 0.0108\n",
      "Epoch 15/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0455 - loss: 0.0108\n",
      "Epoch 16/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0389 - loss: 0.0103\n",
      "Epoch 17/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0624 - loss: 0.0101\n",
      "Epoch 18/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0744 - loss: 0.0095\n",
      "Epoch 19/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.0565 - loss: 0.0100\n",
      "Epoch 20/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0497 - loss: 0.0100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f49b8527c70>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1  # Include padding\n",
    "embedding_dim = 128  # Dimension of embedding space\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "\n",
    "name_input = Input(shape=(max_name_len,))\n",
    "\n",
    "# Embedding layer with masking enabled\n",
    "x = Embedding(vocab_size, embedding_dim, mask_zero=True)(name_input)\n",
    "\n",
    "# LSTM layer for sequence-to-vector encoding\n",
    "x = LSTM(32, return_sequences=False)(x)\n",
    "\n",
    "# Output layer for multi-label classification\n",
    "output = Dense(len(all_labels), activation='sigmoid')(x)\n",
    "\n",
    "# Build the model\n",
    "model = Model(name_input, output)\n",
    "\n",
    "# Compile the model with an optimizer and loss function\n",
    "model.compile(optimizer= optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_padded, Y_train_labels, epochs=20, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3773c9-47b3-4320-b7af-5ca530322df3",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d21fcbf9-a2dc-4bb1-89c1-77bc71de41fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 0.0674 \n",
      "Test Loss: 0.0702538788318634, Test Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test_padded, Y_test_labels, batch_size=32)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50254a8-a931-4a1a-b079-24088864f65d",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "print out the labels with more that 40% chance to appeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b068a4e-b283-4d22-a928-74e1123c7791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Predicted Captures for 'afvigelse': ['nummer', 'oprettet', 'ansvarlig', 'oprettet af', 'projekt nr', 'beskrivelse af afvigelsen', 'afvigelsen skete den']\n"
     ]
    }
   ],
   "source": [
    "# After training, predict using a test book name\n",
    "form_name = \"afvigelse\"\n",
    "name_seq = tokenizer.texts_to_sequences([form_name])\n",
    "name_padded = pad_sequences(name_seq, maxlen=max_name_len, padding='post')\n",
    "\n",
    "predictions = model.predict(name_padded)\n",
    "predicted_labels = (predictions > 0.4).astype(int)  # Apply a threshold to get binary predictions\n",
    "\n",
    "# Convert indices back to capture names\n",
    "predicted_labels = [index_to_label[idx] for idx in np.where(predicted_labels[0] == 1)[0]]\n",
    "\n",
    "print(f\"Predicted Captures for '{form_name}': {predicted_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7391dbb4-5e07-4051-b44b-b6d2bfda2a0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
